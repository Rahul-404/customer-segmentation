{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec78a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b7da4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rahulshelke/Documents/Data-Science/Data-Science-Projects/customer-segmentation/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e114ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc9201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rahulshelke/Documents/Data-Science/Data-Science-Projects/customer-segmentation'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acddb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from typing import Tuple, Union\n",
    "import pandas as pd\n",
    "# from evidently import Report\n",
    "# from evidently.metrics import *\n",
    "# from evidently.presets import *\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from pandas import DataFrame\n",
    "\n",
    "from customer_segmentation.entity.artifact_entity import DataIngestionArtifact#, DataValidationArtifact\n",
    "# from customer_segmentation.entity.config_entity import DataValidationConfig\n",
    "\n",
    "from customer_segmentation.component.data_ingestion import DataIngestion\n",
    "\n",
    "from customer_segmentation.exception import CustomerException\n",
    "from customer_segmentation.logger import logging\n",
    "from customer_segmentation.utils.main_utils import MainUtils, write_yaml_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126eafa",
   "metadata": {},
   "source": [
    "## config_entity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b849cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from customer_segmentation.constant.trainin_pipeline import *\n",
    "\n",
    "TIMESTAMP: str = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b7f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_VALIDATION_DRIFT_REPORT_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dde1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingPieplineConfig:\n",
    "    pipeline_name: str = PIPELINE_NAME\n",
    "    artifact_dir: str = os.path.join(PIPELINE_NAME, ARTIFACT_DIR, TIMESTAMP)\n",
    "    timestamp: str = TIMESTAMP\n",
    "\n",
    "training_pipeline_config: TrainingPieplineConfig = TrainingPieplineConfig()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    data_ingestion_dir: str = os.path.join(training_pipeline_config.artifact_dir,\n",
    "                                           DATA_INGESTION_DIR_NAME)\n",
    "    feature_store_file_path: str = os.path.join(data_ingestion_dir,\n",
    "                                                DATA_INGESTION_FEATURE_STORE_DIR,\n",
    "                                                FILE_NAME)\n",
    "    ingested_data_dir: str = os.path.join(data_ingestion_dir,\n",
    "                                          DATA_INGESTION_INGESTED_DIR)\n",
    "    training_file_path: str = os.path.join(data_ingestion_dir,\n",
    "                                           DATA_INGESTION_INGESTED_DIR, \n",
    "                                           TRAIN_FILE_NAME)\n",
    "    testing_file_path: str = os.path.join(data_ingestion_dir,\n",
    "                                          DATA_INGESTION_INGESTED_DIR,\n",
    "                                          TEST_FILE_NAME)\n",
    "    train_test_split_ratio: float = DATA_INGESTION_TRAIN_TEST_SPLIT_RATIO\n",
    "    collection_name: str = DATA_INGESTION_COLLECTION_NAME\n",
    "\n",
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    data_validation_dir: str = os.path.join(training_pipeline_config.artifact_dir, DATA_VALIDATION_DIR_NAME)\n",
    "    valid_data_dir: str = os.path.join(data_validation_dir, DATA_VALIDATION_VALID_DIR)\n",
    "    invalid_data_dir: str = os.path.join(data_validation_dir, DATA_VALIDATION_INVALID_DIR)\n",
    "    valid_train_file_path: str = os.path.join(data_validation_dir, TRAIN_FILE_NAME)\n",
    "    valid_test_file_path: str = os.path.join(data_validation_dir, TEST_FILE_NAME)\n",
    "    invalid_train_file_path: str = os.path.join(invalid_data_dir, TRAIN_FILE_NAME)\n",
    "    invalid_test_file_path: str = os.path.join(invalid_data_dir, TEST_FILE_NAME)\n",
    "    drift_report_file_path: str = os.path.join(data_validation_dir,\n",
    "                                               DATA_VALIDATION_DRIFT_REPORT_DIR,\n",
    "                                               DATA_VALIDATION_DRIFT_REPORT_FILE_NAME\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182c087",
   "metadata": {},
   "source": [
    "## artifact_entity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f953907",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataIngestionArtifact:\n",
    "    train_file_path: str\n",
    "    test_file_path: str\n",
    "\n",
    "@dataclass\n",
    "class DataValidationArtifact:\n",
    "    validation_status: bool\n",
    "    valid_train_file_path: str\n",
    "    valid_test_file_path: str\n",
    "    invalid_train_file_path: str\n",
    "    invalid_test_file_path: str\n",
    "    drift_report_file_path: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbd20b",
   "metadata": {},
   "source": [
    "## data_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61331f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from typing import Tuple, Union\n",
    "import pandas as pd\n",
    "# from evidently. # for data profiling\n",
    "# from evidently. # for profiling data drift\n",
    "from pandas import DataFrame\n",
    "# from customer_segmentation.entity.config_entity import DataValidationConfig\n",
    "from customer_segmentation.entity.artifact_entity import DataIngestionArtifact#, DataValidationArtifact\n",
    "\n",
    "from customer_segmentation.exception import CustomerException\n",
    "from customer_segmentation.logger import logging\n",
    "from customer_segmentation.utils.main_utils import MainUtils, write_yaml_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "\n",
    "    def __init__(self, data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_config: DataValidationConfig):\n",
    "        self.data_ingestion_artifact = data_ingestion_artifact\n",
    "        self.data_validation_config = data_validation_config\n",
    "        self.utils = MainUtils()\n",
    "        self._schema_config = self.utils.read_schema_config_file()\n",
    "\n",
    "    def validate_schema_columns(self, dataframe: DataFrame) -> bool:\n",
    "        \"\"\" \n",
    "        Method Name : validate_schema_columns\n",
    "        Description : This method validate the schema columns for the particular dataframe\n",
    "\n",
    "        Output      : True or False value is returned based on the schema\n",
    "        On Failure  : Write an exception log and then raise an exception\n",
    "\n",
    "        Version     : 0.1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            status = len(dataframe.columns) == len(self._schema_config[\"columns\"])\n",
    "            logging.info(f\"Is required column present [{status}]\")\n",
    "            return status\n",
    "        except Exception as e:\n",
    "            raise CustomerException(e, sys)\n",
    "        \n",
    "    def validate_dataset_schema_columns(self, train_set, test_set) -> Tuple[bool, bool]:\n",
    "        \"\"\" \n",
    "        Method Name : validate_dataset_schema_columns\n",
    "        Description : This methos validate the schema for shcem columns for both train and test set\n",
    "\n",
    "        Output      : True or False value is returned based on the schema\n",
    "        On Failure  : Write an exception log and then raise an exception\n",
    "        Version     : 0.1\n",
    "        \"\"\"\n",
    "        logging.info(\"Entered validate_dataset_schema_columns method of DataValidationClass\")\n",
    "        try:\n",
    "            logging.info(\"Validating dataset schema columns\")\n",
    "            train_schema_status = self.validate_schema_columns(train_set)\n",
    "            logging.info(\"Validated dataset schema columns on the train set\")\n",
    "            test_schema_status = self.validate_schema_columns(test_set)\n",
    "            logging.info(\"Validated dataset schema columns\")\n",
    "\n",
    "            return train_schema_status, test_schema_status\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomerException(e, sys)\n",
    "        \n",
    "    def detect_dataset_drift(self, reference_df: DataFrame, current_df: DataFrame)-> bool:\n",
    "        \"\"\" \n",
    "        Method Name : detect_dataset_drift\n",
    "        Description : This method deetcts the dataset droft using the reference and production dataframe\n",
    "\n",
    "        Output      : Returns bool or float value based on the get_ration parameter\n",
    "        On Failure  : Write an exception log and then raise an exception\n",
    "\n",
    "        Version     : 0.1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_drift_profile = Report([DataDriftPreset()])\n",
    "            data_drift_profile.run(reference_data=reference_df, current_data=current_df)\n",
    "            report = data_drift_profile.json()\n",
    "            json_report = json.loads(report)\n",
    "            # writing the report as json\n",
    "            write_yaml_file(file_path=self.data_validation_config.drift_report_file_path, content=json_report)\n",
    "\n",
    "            n_features = json_report[\"metrics\"][0][\"result\"][\"number_of_columns\"]\n",
    "\n",
    "            n_drifted_features = json_report[\"metrics\"][0][\"result\"][\"number_of_drifted_columns\"]\n",
    "            \n",
    "            logging.info(f\"{n_drifted_features}/{n_features} drift detected.\")\n",
    "\n",
    "            drift_status = json_report[\"metrics\"][0][\"result\"][\"dataset_drift\"]\n",
    "\n",
    "            return drift_status\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomerException(e, sys)\n",
    "        \n",
    "    @staticmethod\n",
    "    def read_data(file_path) -> DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            raise CustomerException(e, sys)\n",
    "        \n",
    "    def initiate_data_validation(self) -> DataValidationArtifact:\n",
    "        \"\"\"\n",
    "        Method Name :   initiate_data_validation\n",
    "        Description :   This method initiates the data validation component for the pipeline\n",
    "        \n",
    "        Output      :   Returns bool value based on validation results\n",
    "        On Failure  :   Write an exception log and then raise an exception\n",
    "        \n",
    "        Version     :   0.1\n",
    "        \"\"\"\n",
    "        logging.info(\"Entered initiate_data_validation method of Data_Validation class\")\n",
    "\n",
    "        try:\n",
    "            logging.info(\"Initiated data validation for the dataset\")\n",
    "\n",
    "            train_df, test_df = (DataValidation.read_data(file_path = self.data_ingestion_artifact.train_file_path),\n",
    "                                DataValidation.read_data(file_path = self.data_ingestion_artifact.test_file_path))\n",
    "            \n",
    "            \n",
    "            \n",
    "            drift = self.detect_dataset_drift(train_df, test_df)\n",
    "\n",
    "            (\n",
    "                schema_train_col_status,\n",
    "                schema_test_col_status,\n",
    "            ) = self.validate_dataset_schema_columns(train_set=train_df, test_set=test_df)\n",
    "\n",
    "            logging.info(\n",
    "                f\"Schema train cols status is {schema_train_col_status} and schema test cols status is {schema_test_col_status}\"\n",
    "            )\n",
    "\n",
    "            logging.info(\"Validated dataset schema columns\")\n",
    "\n",
    "            \n",
    "\n",
    "            if (\n",
    "                schema_train_col_status is True\n",
    "                and schema_test_col_status is True\n",
    "                and drift is False\n",
    "            ):\n",
    "                logging.info(\"Dataset schema validation completed\")\n",
    "\n",
    "                validation_status = True\n",
    "            else:\n",
    "                validation_status = False\n",
    "            \n",
    "            data_validation_artifact = DataValidationArtifact(\n",
    "                validation_status=validation_status,\n",
    "                valid_train_file_path=self.data_ingestion_artifact.train_file_path,\n",
    "                valid_test_file_path=self.data_ingestion_artifact.test_file_path,\n",
    "                invalid_train_file_path=self.data_validation_config.invalid_train_file_path,\n",
    "                invalid_test_file_path=self.data_validation_config.invalid_test_file_path,\n",
    "                drift_report_file_path=self.data_validation_config.drift_report_file_path\n",
    "            )\n",
    "\n",
    "            return data_validation_artifact\n",
    "        except Exception as e:\n",
    "            raise CustomerException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b0203d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataValidationArtifact(validation_status=True, valid_train_file_path='customer_segmentation/artifact/05_06_2025_11_39_18/data_ingestion/ingested/train.csv', valid_test_file_path='customer_segmentation/artifact/05_06_2025_11_39_18/data_ingestion/ingested/test.csv', invalid_train_file_path='customer_segmentation/artifact/05_06_2025_11_46_53/data_validation/invalid/train.csv', invalid_test_file_path='customer_segmentation/artifact/05_06_2025_11_46_53/data_validation/invalid/test.csv', drift_report_file_path='customer_segmentation/artifact/05_06_2025_11_46_53/data_validation/drift_report/report.yaml')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # print(os.getcwd())\n",
    "    data_ingestion_object = DataIngestion()\n",
    "    data_ingestion_artifact = data_ingestion_object.initiate_data_ingestion()\n",
    "\n",
    "    data_validation_object = DataValidation(data_ingestion_artifact=data_ingestion_artifact, \n",
    "                                            data_validation_config=DataValidationConfig)\n",
    "    data_validation_artifact = data_validation_object.initiate_data_validation()\n",
    "    print(data_validation_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136b464",
   "metadata": {},
   "source": [
    "## Evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd6171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python version: 3.8.20\n",
    "# !pip install evidently==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc04d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evidently\n",
    "evidently.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be494625",
   "metadata": {},
   "source": [
    "## Data Drift Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25bdc1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rahulshelke/Documents/Data-Science/Data-Science-Projects/customer-segmentation'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe64190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"notebooks/data/marketing_campaign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec0e717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04-09-2012</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08-03-2014</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-02-2014</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  AcceptedCmp3  \\\n",
       "0  04-09-2012       58       635  ...                  7             0   \n",
       "1  08-03-2014       38        11  ...                  5             0   \n",
       "2  21-08-2013       26       426  ...                  4             0   \n",
       "3  10-02-2014       26        11  ...                  6             0   \n",
       "4  19-01-2014       94       173  ...                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  \\\n",
       "0             0             0             0             0         0   \n",
       "1             0             0             0             0         0   \n",
       "2             0             0             0             0         0   \n",
       "3             0             0             0             0         0   \n",
       "4             0             0             0             0         0   \n",
       "\n",
       "   Z_CostContact  Z_Revenue  Response  \n",
       "0              3         11         1  \n",
       "1              3         11         0  \n",
       "2              3         11         0  \n",
       "3              3         11         0  \n",
       "4              3         11         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee11e256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2240, 29)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fe8dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"ID\", \"Z_CostContact\", \"Z_Revenue\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b72f737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2240, 26)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f540ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year_Birth', 'Education', 'Marital_Status', 'Income', 'Kidhome',\n",
       "       'Teenhome', 'Dt_Customer', 'Recency', 'MntWines', 'MntFruits',\n",
       "       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
       "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
       "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
       "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
       "       'AcceptedCmp2', 'Complain', 'Response'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00560e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa630751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data drift opbject\n",
    "data_drift_profile = Report([\n",
    "    DataDriftPreset()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96ec9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data drift report\n",
    "# data_drift_report = \n",
    "data_drift_profile.run(reference_data=train_set, current_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08d264ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evidently.report.report.Report"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_drift_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da795b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = data_drift_profile.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91775962",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_report = json.loads(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c303ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = json_report[\"metrics\"][0][\"result\"][\"number_of_columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4a28606",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_drifted_features = json_report[\"metrics\"][0][\"result\"][\"number_of_drifted_columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efde53d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/26 drift detected.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{n_drifted_features}/{n_features} drift detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "724b47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_status = json_report[\"metrics\"][0][\"result\"][\"dataset_drift\"]\n",
    "\n",
    "drift_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7456df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
